{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ebd9d1b",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "---\n",
    "Take the raw data from `/data/hamSpam.csv` and `/data/phish.csv` and conform the ham/spam dataset to the structure of the phishing dataset and integrate together. Then clean the dataset by removing NA values, standardize the textual features by lowercasing and removing stopwords, and remove any embedded HTML elements from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d087e",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/prokope/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from utils import clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b66040",
   "metadata": {},
   "source": [
    "Download nltk datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb1bd77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/prokope/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/prokope/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/prokope/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK downloads\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff466ba0",
   "metadata": {},
   "source": [
    "## 2. Load Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "caa72205",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamSpam_df = pd.read_csv(\"./data/1_hamSpam.csv\")\n",
    "phish_df = pd.read_csv(\"./data/1_phish.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6af1e",
   "metadata": {},
   "source": [
    "## 3. Process Ham/Spam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6717d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename known columns (no error if source names are missing)\n",
    "hamSpam_df.rename(\n",
    "    columns={\"Spam/Ham\": \"Email Type\", \"Message\": \"Email Text\"},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Drop optional columns only if they exist to avoid KeyError\n",
    "cols_to_drop = [c for c in [\"Date\", \"Subject\"] if c in hamSpam_df.columns]\n",
    "\n",
    "if cols_to_drop:\n",
    "\thamSpam_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Filter out emails that are not ham/spam\n",
    "hamSpam_df = hamSpam_df[hamSpam_df['Email Type'].isin(['ham', 'spam'])]\n",
    "\n",
    "# Export as processed dataset\n",
    "hamSpam_df.to_feather(\n",
    "    \"data/2_hamSpam_processed.feather\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbf923",
   "metadata": {},
   "source": [
    "## 4. Process Phishing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16281a1",
   "metadata": {},
   "source": [
    "Observe email types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "498aead1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'Safe Email'\", \"'Phishing Email'\"], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_df['Email Type'].apply(repr).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a9b71",
   "metadata": {},
   "source": [
    "Standardize email types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20061877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'ham'\", \"'phish'\"], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_df['Email Type'] = phish_df['Email Type'].replace(\n",
    "    {'Safe Email': 'ham', 'Phishing Email': 'phish'}\n",
    ")\n",
    "phish_df['Email Type'].apply(repr).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db54d59",
   "metadata": {},
   "source": [
    "## 5. Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a1953e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'ham'\", \"'spam'\", \"'phish'\"], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_df = pd.concat([hamSpam_df, phish_df], ignore_index=True)\n",
    "email_df['Email Type'].apply(repr).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db94af",
   "metadata": {},
   "source": [
    "Show total count of emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0b5c082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Email Text    52298\n",
       "Email Type    52366\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c308d54c",
   "metadata": {},
   "source": [
    "## 6. Drop NA and \"empty\" Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c190657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Text    68\n",
      "Email Type     0\n",
      "dtype: int64\n",
      "Email Text    0\n",
      "Email Type    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(email_df.isna().sum())\n",
    "\n",
    "email_df.dropna(inplace=True)\n",
    "\n",
    "empty_rows = email_df[email_df[\"Email Text\"] == \"empty\"]\n",
    "email_df.drop(empty_rows.index, inplace=True)\n",
    "\n",
    "print(email_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ad3c0",
   "metadata": {},
   "source": [
    "## 7. Bulk Clean Dataset & Export to CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6718ee3",
   "metadata": {},
   "source": [
    "Clean data by removing stop words, punctuation, special characters, and tokenize/lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f881c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "      <th>Cleaned Email Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gary , production from the high island larger ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>gary production high island larger block comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- calpine daily gas nomination 1 . doc</td>\n",
       "      <td>ham</td>\n",
       "      <td>calpine daily gas nomination doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fyi - see note below - already done .\\nstella\\...</td>\n",
       "      <td>ham</td>\n",
       "      <td>fyi see note already done stella forwarded ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi .\\n- - - - - - - - - - - - - - - - - - - -...</td>\n",
       "      <td>ham</td>\n",
       "      <td>fyi forwarded lauri allen hou ect pm kimberly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jackie ,\\nsince the inlet to 3 river plant is ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>jackie since inlet river plant shut last day f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52360</th>\n",
       "      <td>\\nRick Moen  a Ã©crit:&gt; &gt; I'm confused. I thou...</td>\n",
       "      <td>ham</td>\n",
       "      <td>rick moen im confused thought gpled money paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52361</th>\n",
       "      <td>date a lonely housewife always wanted to date ...</td>\n",
       "      <td>phish</td>\n",
       "      <td>date lonely housewife always wanted date lonel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52362</th>\n",
       "      <td>request submitted : access request for anita ....</td>\n",
       "      <td>ham</td>\n",
       "      <td>request submitted access request anita dupont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52363</th>\n",
       "      <td>re : important - prc mtg hi dorn &amp; john , as y...</td>\n",
       "      <td>ham</td>\n",
       "      <td>important prc mtg hi dorn john discovered rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52364</th>\n",
       "      <td>press clippings - letter on californian utilit...</td>\n",
       "      <td>ham</td>\n",
       "      <td>press clipping letter californian utility plea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51765 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Email Text Email Type  \\\n",
       "1      gary , production from the high island larger ...        ham   \n",
       "2                 - calpine daily gas nomination 1 . doc        ham   \n",
       "3      fyi - see note below - already done .\\nstella\\...        ham   \n",
       "4      fyi .\\n- - - - - - - - - - - - - - - - - - - -...        ham   \n",
       "5      jackie ,\\nsince the inlet to 3 river plant is ...        ham   \n",
       "...                                                  ...        ...   \n",
       "52360  \\nRick Moen  a Ã©crit:> > I'm confused. I thou...        ham   \n",
       "52361  date a lonely housewife always wanted to date ...      phish   \n",
       "52362  request submitted : access request for anita ....        ham   \n",
       "52363  re : important - prc mtg hi dorn & john , as y...        ham   \n",
       "52364  press clippings - letter on californian utilit...        ham   \n",
       "\n",
       "                                      Cleaned Email Text  \n",
       "1      gary production high island larger block comme...  \n",
       "2                       calpine daily gas nomination doc  \n",
       "3      fyi see note already done stella forwarded ste...  \n",
       "4      fyi forwarded lauri allen hou ect pm kimberly ...  \n",
       "5      jackie since inlet river plant shut last day f...  \n",
       "...                                                  ...  \n",
       "52360  rick moen im confused thought gpled money paid...  \n",
       "52361  date lonely housewife always wanted date lonel...  \n",
       "52362  request submitted access request anita dupont ...  \n",
       "52363  important prc mtg hi dorn john discovered rece...  \n",
       "52364  press clipping letter californian utility plea...  \n",
       "\n",
       "[51765 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_email_df = email_df.copy()\n",
    "cleaned_email_df[\"Cleaned Email Text\"] = email_df[\"Email Text\"].apply(clean_text)\n",
    "cleaned_email_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec7b69",
   "metadata": {},
   "source": [
    "Export to feather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eaa65c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_email_df.to_feather(\n",
    "    \"./data/2_clean_email_dataset.feather\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
