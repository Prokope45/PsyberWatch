{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7baeebb6",
   "metadata": {},
   "source": [
    "# Analyze Dataset\n",
    "---\n",
    "1. Encode email data using BERT.\n",
    "2. Split data into test and train splits.\n",
    "3. Train an SVM model to predict the class of an email.\n",
    "4. Test the model on unseen emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566797a8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d60c41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import joblib\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf55cd",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f63d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_dataframe = pd.read_feather(\"./data/2_balanced_email_dataset.feather\")\n",
    "\n",
    "# Encode \"Email Type\" into a numerical format: 0 for ham, 1 for phishing, and 2 for spam\n",
    "email_dataframe[\"label_id\"] = email_dataframe[\"Email Type\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03fdae",
   "metadata": {},
   "source": [
    "## Encode Email Text using SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33647260",
   "metadata": {},
   "source": [
    "Activate CUDA if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36412e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'device' (str)\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if platform.system() == \"Windows\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "elif platform.system() == \"Darwin\":\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# Store the variable to be used in 5. Demo Classify Emails.ipynb\n",
    "%store device\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c8ebcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1610/1610 [02:43<00:00,  9.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load a BERT-based encoder\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "# Encode emails\n",
    "X = model.encode(\n",
    "    email_dataframe['Email Text'].tolist(),\n",
    "    convert_to_numpy=True,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2181817f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      3434\n",
      "           1       0.95      0.96      0.96      3434\n",
      "           2       1.00      1.00      1.00      3435\n",
      "\n",
      "    accuracy                           0.97     10303\n",
      "   macro avg       0.97      0.97      0.97     10303\n",
      "weighted avg       0.97      0.97      0.97     10303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "y = email_dataframe['label_id']\n",
    "\n",
    "# Train / Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train SVM classifier\n",
    "clf = SVC(kernel=\"linear\", class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97ad72",
   "metadata": {},
   "source": [
    "Save as `.joblib` file for later reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98b3e767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/svm_model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"./models\").mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(clf, \"./models/svm_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc1469",
   "metadata": {},
   "source": [
    "### Alternative: Use Raw BERT via HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b82740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# import numpy as np\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# model.eval()\n",
    "\n",
    "# def bert_encode(text):\n",
    "#     inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=256)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     cls_embedding = outputs.last_hidden_state[:,0,:].numpy()   # CLS token\n",
    "#     return cls_embedding.flatten()\n",
    "\n",
    "# # Encode entire column\n",
    "# X = np.vstack([bert_encode(t) for t in email_dataframe['Email Text']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
